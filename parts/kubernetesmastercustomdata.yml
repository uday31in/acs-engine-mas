#cloud-config

packages:
 - etcd
 - jq
 - traceroute

write_files:
- path: "/etc/kubernetes/azurestackcloud.json"
  permissions: "0644"
  owner: "root"
  content: |
    {
        "name": "AzurestackCloud",
        "managementPortalURL": "https://manage.windowsazure.com/",
        "publishSettingsURL": "https://manage.windowsazure.com/publishsettings/index",
        "serviceManagementEndpoint": "https://management.uday365.com/46d1ebf1-e789-44f9-bfea-b0353fe066d3",
        "resourceManagerEndpoint": "https://management.local.azurestack.external",
        "activeDirectoryEndpoint": "https://login.windows.net/",
        "galleryEndpoint": "https://adminportal.local.azurestack.external:30015/",
        "keyVaultEndpoint": "https://vault.azure.net/",
        "graphEndpoint": "https://graph.windows.net/",
        "storageEndpointSuffix": "local.azurestack.external",
        "sqlDatabaseDNSSuffix": "database.windows.net",
        "trafficManagerDNSSuffix": "trafficmanager.net",
        "keyVaultDNSSuffix": "vault.local.azurestack.external",
        "serviceBusEndpointSuffix": "servicebus.azure.com",
        "serviceManagementVMDNSSuffix": "cloudapp.net",
        "resourceManagerVMDNSSuffix": "cloudapp.azure.com",
        "containerRegistryDNSSuffix": "azurecr.io"
    }

- path: "/usr/local/share/ca-certificates/azurestack.crt"
  permissions: "0644"
  encoding: "base64"
  owner: "root"
  content: |
    LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tDQpNSUlGWkRDQ0EweWdBd0lCQWdJUWYvV1FZT29zZ3J0SmhoNElTVk5VM1RBTkJna3Foa2lHOXcwQkFRc0ZBREFuDQpNU1V3SXdZRFZRUUREQnhCZW5WeVpWTjBZV05yVTJWc1psTnBaMjVsWkZKdmIzUkRaWEowTUI0WERURTNNRGd6DQpNVEUyTkRNd05Wb1hEVEU0TURnek1URTNNRE13TlZvd0p6RWxNQ01HQTFVRUF3d2NRWHAxY21WVGRHRmphMU5sDQpiR1pUYVdkdVpXUlNiMjkwUTJWeWREQ0NBaUl3RFFZSktvWklodmNOQVFFQkJRQURnZ0lQQURDQ0Fnb0NnZ0lCDQpBTVc0cXg4SVJ2R0lKTTFjRlk2OTk0RnEzZTJTVnFWNHdid05XSG5iUlNLWVlFR0g1NjIwbjRHRUxYNCtyKzV2DQpTaktTNzMzZmlnUmM2QktpanZVSk9wUXd4cUwzdGQ4WnQzNXhLOVhCZzBjaG9GQk9obS9OLzl3eGRqQ2UzcGhtDQpaSXVoR1YzUGlFK2czT0YzeFhvaFRuL25YOTVnZDJSbnBpUEhldVBjNzNDZXJKcmF3Umo5ajNzSlRqazR5eit0DQpBZU5JNEpseDQ2VG84cjUwT01uQUVub21sQ0lsdmM5TEFSTHl0dkZCT3pSc01FcE9ONVpVak84S3NRR3JDZmJlDQpaY0tNY0FLSm5pUnI0YU54STlwRDZkYSszUFJEWm5NcExNdXpGMG9UNG04T0RYL21lcjduQmtoSk93QTd4SEMvDQp3RzJoWG9QWE9ONmNHa2pLV2tzcVNBUHFhQURtYmg0ZEVtMEU3Nm0vaHpaNVpSSUMwOFVPbG44cGNGaFhwNmJqDQpTamNnczVVRkhHdUY5MXZKRGdReDYwT1ZkeW1zVmxKQXBrUGNwUVUzNnhIMlJCRU4yQ0NtZ1lZWUZHSFpMbStIDQpVOEw5RmI5WkZaZFp1UDV5ejB3d1Y4aDdYRXg5YXIrRUpZVlpXcHp4S3NNK3FpNTdTMDR6a0duc1BYb0RYTktzDQpqWjVEZ1NFQi85MEt0Qmt3R3hrUmRrSk8rMnhCTW0vb1FkK280bnp2eHlWWjJyZG1UaElJSXU2bFhIdmI2SnhtDQpFdjlwTlJ5RmhLSjNYZkcwZ293L3Jya3hTaXBiYmRHNDdBV2cwM3BGZ1UreGJwajdzYnk2bWs0S0N2VWtLOFhhDQpHTU85dWhHYzFVcGs4M24zdzg2NUVMSmdtcm0xU2IzSlhvSWlGWEdia3JhSkFnTUJBQUdqZ1lzd2dZZ3dEZ1lEDQpWUjBQQVFIL0JBUURBZ0kwTUIwR0ExVWRKUVFXTUJRR0NDc0dBUVVGQndNQ0JnZ3JCZ0VGQlFjREFUQWtCZ05WDQpIUkVFSFRBYmdobHNiMk5oYkM1aGVuVnlaWE4wWVdOckxtVjRkR1Z5Ym1Gc01CSUdBMVVkRXdFQi93UUlNQVlCDQpBZjhDQVFNd0hRWURWUjBPQkJZRUZLWXJuN25Hd0ZTY2ZJSWxTRlBQSHNQK2FRUktNQTBHQ1NxR1NJYjNEUUVCDQpDd1VBQTRJQ0FRQXg4dVYyV3dFVTdjQ3hGQy9IOW9pUTNodE1IcXcrVlVsdFA2Y3pFRHhzYVVuejBWMjk5STZKDQptMHdlbklqSlc3VnpTc1pOSXFiaitSOUQwZ0svMG5LcER2b2Fad3hKN05aRU5hQTdabUJVVFZ2bE9scDN0Q05EDQo0Y1AvQXI1a1JjODdlOHdXS2NFUU9Fa3ZWUVU2bndvdFdld3piaEdVUDFwaXZFblhVVENhZkN6aTY1NFFvSE9oDQo4WWN6LytnTEpMZGdEclNrc1FScTljZ3dDb1N5aENyV01NdVM0cWtBakxJOHNHNlMyTWpMYjF3M0hjRnh5Nkt0DQpqRlRBZzhrQnBOeUovVmtSSzY0MGsyN0FUZWNGYVY1alJzS3kxWThULzIyWG0xc0VtMVJxb3VDMDVoQk9wOXpFDQo2ZlF0Z0dIUndCZHBSNHhRUjI2akEvcnVUQlluVUlMazVWV2ptM0JzWUUvbG5kVmhQVkNmVE9XL0tOVlhHdC9LDQordld2Um5wZjcyQU12dlRpQmxrNzViMmQxZWhvWWNNa0pQK2F3NUhJeC9PcE5Ec2xaVlZ3djcvQ2M5K2Q1UzNXDQpJeFYvbmc0aHVqcEJvdmVWNlpaTlNNbTJwUWFrcE5weTdzcjFuNlpOSFFzWE5rU3ltOWppV3pFVXBBbXhJNUJQDQpKenIvVjFMQXpzUHJqajdYWXVNdXk0SlM3ZDg5YXhsZGFXSUJBaG83Rnd1dVdYaXNjM3hVYUpXSFpQOTEwNmVTDQpKWmliZ2xJbFRzN3pxYWwrZXdNLy9CRWNyREI4dDlMaU55NlZjVU4xRWtVSTRuOTZaVzk2ZUVPUnZMeWlmdkRTDQpWU083Tmx2SGk5SFJ1YXFDaTg4bVNPR2JTbkpCVnorR2orNW5lVktudWNJR1hZZkFweDlFWFE9PQ0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQ0K

- path: "/etc/systemd/system/docker.service.d/clear_mount_propagation_flags.conf"
  permissions: "0644"
  owner: "root"
  content: |
    [Service]
    MountFlags=shared

- path: "/etc/systemd/system/docker.service.d/exec_start.conf"
  permissions: "0644"
  owner: "root"
  content: |
    [Service]
    ExecStart=
    ExecStart=/usr/bin/docker daemon -H fd:// --storage-driver=overlay --bip={{WrapAsVariable "dockerBridgeCidr"}}

- path: "/etc/docker/daemon.json"
  permissions: "0644"
  owner: "root"
  content: |
    {
      "live-restore": true,
      "log-driver": "json-file",
      "log-opts":  {
         "max-size": "50m",
         "max-file": "5"
      }
    }

- path: "/etc/kubernetes/certs/ca.crt"
  permissions: "0644"
  encoding: "base64"
  owner: "root"
  content: |
    {{WrapAsVariable "caCertificate"}}

- path: "/etc/kubernetes/certs/apiserver.crt"
  permissions: "0644"
  encoding: "base64"
  owner: "root"
  content: |
    {{WrapAsVariable "apiServerCertificate"}}

- path: "/etc/kubernetes/certs/client.crt"
  permissions: "0644"
  encoding: "base64"
  owner: "root"
  content: |
    {{WrapAsVariable "clientCertificate"}}

- path: "/var/lib/kubelet/kubeconfig"
  permissions: "0644"
  owner: "root"
  content: |
    apiVersion: v1
    kind: Config
    clusters:
    - name: localcluster
      cluster:
        certificate-authority: /etc/kubernetes/certs/ca.crt
        server: {{WrapAsVerbatim "concat('https://', variables('masterPrivateIpAddrs')[copyIndex(variables('masterOffset'))], ':443')"}}
    users:
    - name: client
      user:
        client-certificate: /etc/kubernetes/certs/client.crt
        client-key: /etc/kubernetes/certs/client.key
    contexts:
    - context:
        cluster: localcluster
        user: client
      name: localclustercontext
    current-context: localclustercontext

- path: /etc/kubernetes/manifests/kube-apiserver.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_KUBERNETES_APISERVER_B64_GZIP_STR

- path: /etc/kubernetes/manifests/kube-controller-manager.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_KUBERNETES_CONTROLLER_MANAGER_B64_GZIP_STR

- path: /etc/kubernetes/manifests/kube-scheduler.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_KUBERNETES_SCHEDULER_B64_GZIP_STR

- path: /etc/kubernetes/manifests/kube-addon-manager.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_KUBERNETES_ADDON_MANAGER_B64_GZIP_STR

- path: /etc/kubernetes/addons/kube-dns-deployment.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_ADDON_KUBE_DNS_DEPLOYMENT_B64_GZIP_STR

- path: /etc/kubernetes/addons/kube-proxy-daemonset.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_ADDON_KUBE_PROXY_DAEMONSET_B64_GZIP_STR

- path: /etc/kubernetes/addons/kubernetes-dashboard-deployment.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_ADDON_KUBERNETES_DASHBOARD_DEPLOYMENT_B64_GZIP_STR

- path: /etc/kubernetes/addons/kube-heapster-deployment.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_ADDON_HEAPSTER_DEPLOYMENT_B64_GZIP_STR

- path: /etc/kubernetes/addons/azure-storage-classes.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_ADDON_AZURE_STORAGE_CLASSES_B64_GZIP_STR

- path: /etc/kubernetes/addons/kube-tiller-deployment.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_ADDON_TILLER_DEPLOYMENT_B64_GZIP_STR

{{if eq .OrchestratorProfile.KubernetesConfig.NetworkPolicy "calico"}}
- path: /etc/kubernetes/addons/calico-daemonset.yaml
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    MASTER_ADDON_CALICO_DAEMONSET_B64_GZIP_STR
{{end}}

- path: "/etc/systemd/system/kubectl-extract.service"
  permissions: "0644"
  owner: "root"
  content: |
    [Unit]
    Description=Kubectl extraction
    Requires=docker.service
    After=docker.service
    ConditionPathExists=!/usr/local/bin/kubectl

    [Service]
    TimeoutStartSec=0
    Restart=on-failure
    RestartSec=5s
    ExecStartPre=/bin/mkdir -p /tmp/kubectldir
    ExecStartPre=/usr/bin/docker pull {{WrapAsVariable "kubernetesHyperkubeSpec"}}
    ExecStartPre=/usr/bin/docker run --rm -v /tmp/kubectldir:/opt/kubectldir {{WrapAsVariable "kubernetesHyperkubeSpec"}} /bin/bash -c "cp /hyperkube /opt/kubectldir/"
    ExecStartPre=/bin/mv /tmp/kubectldir/hyperkube /usr/local/bin/kubectl
    ExecStart=/bin/chmod a+x /usr/local/bin/kubectl

    [Install]
    WantedBy=multi-user.target

- path: "/etc/default/kubelet"
  permissions: "0644"
  owner: "root"
  content: |
    KUBELET_CLUSTER_DNS={{WrapAsVariable "kubeDnsServiceIP"}}
    KUBELET_API_SERVERS={{WrapAsVerbatim "concat('https://', variables('masterPrivateIpAddrs')[copyIndex(variables('masterOffset'))], ':443')"}}
    KUBELET_IMAGE={{WrapAsVariable "kubernetesHyperkubeSpec"}}
    KUBELET_NETWORK_PLUGIN=
    KUBELET_MAX_PODS=110
    DOCKER_OPTS=
    KUBELET_NODE_LABELS=role=master
    KUBELET_POD_INFRA_CONTAINER_IMAGE={{WrapAsVariable "kubernetesPodInfraContainerSpec"}}
    KUBELET_NODE_STATUS_UPDATE_FREQUENCY={{WrapAsVariable "kubernetesNodeStatusUpdateFrequency"}}
    KUBE_CTRL_MGR_NODE_MONITOR_GRACE_PERIOD={{WrapAsVariable "kubernetesCtrlMgrNodeMonitorGracePeriod"}}
    KUBE_CTRL_MGR_POD_EVICTION_TIMEOUT={{WrapAsVariable "kubernetesCtrlMgrPodEvictionTimeout"}}
    KUBE_CTRL_MGR_ROUTE_RECONCILIATION_PERIOD={{WrapAsVariable "kubernetesCtrlMgrRouteReconciliationPeriod"}}
{{if IsKubernetesVersionGe "1.6.0"}}
  {{if HasLinuxAgents}}
    KUBELET_REGISTER_NODE=--register-node=true
    KUBELET_REGISTER_WITH_TAINTS=--register-with-taints={{WrapAsVariable "registerWithTaints"}}
  {{end}}
{{else}}
    KUBELET_REGISTER_SCHEDULABLE={{WrapAsVariable "registerSchedulable"}}
{{end}}
- path: "/etc/systemd/system/kubelet.service"
  permissions: "0644"
  encoding: gzip
  owner: "root"
  content: !!binary |
    KUBELET_SERVICE_B64_GZIP_STR

- path: "/opt/azure/containers/kubelet.sh"
  permissions: "0755"
  owner: "root"
  content: |
    #!/bin/bash
    set -e

{{if gt .MasterProfile.Count 1}}
    # Azure does not support two LoadBalancers(LB) sharing the same nic and backend port.
    # As a workaround, the Internal LB(ILB) listens for apiserver traffic on port 4443 and the External LB(ELB) on port 443
    # This IPTable rule then redirects ILB traffic to port 443 in the prerouting chain
    iptables -t nat -A PREROUTING -p tcp --dport 4443 -j REDIRECT --to-port 443
{{end}}

{{if IsVNETIntegrated}}
    # SNAT outbound traffic from pods to destinations outside of VNET.
    iptables -t nat -A POSTROUTING -m iprange ! --dst-range 168.63.129.16 -m addrtype ! --dst-type local ! -d {{WrapAsVariable "vnetCidr"}} -j MASQUERADE
{{end}}

    sed -i "s|<kubernetesAddonManagerSpec>|{{WrapAsVariable "kubernetesAddonManagerSpec"}}|g" "/etc/kubernetes/manifests/kube-addon-manager.yaml"
    sed -i "s|<kubernetesHyperkubeSpec>|{{WrapAsVariable "kubernetesHyperkubeSpec"}}|g; s|<kubeServiceCidr>|{{WrapAsVariable "kubeServiceCidr"}}|g; s|<masterEtcdClientPort>|{{WrapAsVariable "masterEtcdClientPort"}}|g; s|<kubernetesAPIServerIP>|{{WrapAsVariable "kubernetesAPIServerIP"}}|g" "/etc/kubernetes/manifests/kube-apiserver.yaml"
    sed -i "s|<kubernetesHyperkubeSpec>|{{WrapAsVariable "kubernetesHyperkubeSpec"}}|g; s|<masterFqdnPrefix>|{{WrapAsVariable "masterFqdnPrefix"}}|g; s|<allocateNodeCidrs>|{{WrapAsVariable "allocateNodeCidrs"}}|g; s|<kubeClusterCidr>|{{WrapAsVariable "kubeClusterCidr"}}|g; s|<kubernetesCtrlMgrNodeMonitorGracePeriod>|{{WrapAsVariable "kubernetesCtrlMgrNodeMonitorGracePeriod"}}|g; s|<kubernetesCtrlMgrPodEvictionTimeout>|{{WrapAsVariable "kubernetesCtrlMgrPodEvictionTimeout"}}|g; s|<kubernetesCtrlMgrRouteReconciliationPeriod>|{{WrapAsVariable "kubernetesCtrlMgrRouteReconciliationPeriod"}}|g" "/etc/kubernetes/manifests/kube-controller-manager.yaml"
    sed -i "s|<kubernetesHyperkubeSpec>|{{WrapAsVariable "kubernetesHyperkubeSpec"}}|g" "/etc/kubernetes/manifests/kube-scheduler.yaml"
    sed -i "s|<kubernetesHyperkubeSpec>|{{WrapAsVariable "kubernetesHyperkubeSpec"}}|g; s|<kubeClusterCidr>|{{WrapAsVariable "kubeClusterCidr"}}|g" "/etc/kubernetes/addons/kube-proxy-daemonset.yaml"
    sed -i "s|<kubernetesKubeDNSSpec>|{{WrapAsVariable "kubernetesKubeDNSSpec"}}|g; s|<kubernetesDNSMasqSpec>|{{WrapAsVariable "kubernetesDNSMasqSpec"}}|g; s|<kubernetesExecHealthzSpec>|{{WrapAsVariable "kubernetesExecHealthzSpec"}}|g" "/etc/kubernetes/addons/kube-dns-deployment.yaml"
    sed -i "s|<kubernetesHeapsterSpec>|{{WrapAsVariable "kubernetesHeapsterSpec"}}|g; s|<kubernetesAddonResizerSpec>|{{WrapAsVariable "kubernetesAddonResizerSpec"}}|g" "/etc/kubernetes/addons/kube-heapster-deployment.yaml"
    sed -i "s|<kubernetesDashboardSpec>|{{WrapAsVariable "kubernetesDashboardSpec"}}|g" "/etc/kubernetes/addons/kubernetes-dashboard-deployment.yaml"
    sed -i "s|<kubernetesTillerSpec>|{{WrapAsVariable "kubernetesTillerSpec"}}|g" "/etc/kubernetes/addons/kube-tiller-deployment.yaml"

{{if .OrchestratorProfile.KubernetesConfig.EnableRbac }}
    # If RBAC enabled then add parameters to API server and Controller manager configuration
    sed -i "s|<kubernetesEnableRbac>|--authorization-mode=RBAC|g" "/etc/kubernetes/manifests/kube-apiserver.yaml"
    sed -i "s|<kubernetesEnableRbac>|--use-service-account-credentials|g" "/etc/kubernetes/manifests/kube-controller-manager.yaml"
{{else}}
    sed -i "/<kubernetesEnableRbac>/d" "/etc/kubernetes/manifests/kube-apiserver.yaml"
    sed -i "/<kubernetesEnableRbac>/d" "/etc/kubernetes/manifests/kube-controller-manager.yaml"
{{end}}

{{if eq .OrchestratorProfile.KubernetesConfig.NetworkPolicy "calico"}}
    # If Calico Policy enabled then update Cluster Cidr
    sed -i "s|<kubeClusterCidr>|{{WrapAsVariable "kubeClusterCidr"}}|g" "/etc/kubernetes/addons/calico-daemonset.yaml"
{{end}}

- path: "/opt/azure/containers/provision.sh"
  permissions: "0744"
  encoding: gzip
  owner: "root"
  content: !!binary |
    {{WrapAsVariable "provisionScript"}}

- path: "/opt/azure/containers/mountetcd.sh"
  permissions: "0744"
  owner: "root"
  content: |
    #!/bin/bash
    # Mounting is done here instead of etcd because of bug https://bugs.launchpad.net/cloud-init/+bug/1692093
    # Once the bug is fixed, replace the below with the cloud init changes replaced in https://github.com/Azure/acs-engine/pull/661.
    set -x
    DISK=/dev/sdc
    PARTITION=${DISK}1
    MOUNTPOINT=/var/lib/etcddisk
    udevadm settle
    mkdir -p $MOUNTPOINT
    mount | grep $MOUNTPOINT
    if [ $? -eq 0 ]
    then
        echo "disk is already mounted"
        exit 0
    fi
    # fill /etc/fstab
    grep "/dev/sdc1" /etc/fstab
    if [ $? -ne 0 ]
    then
        echo "$PARTITION       $MOUNTPOINT       auto    defaults,nofail       0       2" >> /etc/fstab
    fi
    # check if partition exists
    ls $PARTITION
    if [ $? -ne 0 ]
    then
        # partition does not exist
        /sbin/sgdisk --new 1 $DISK
        /sbin/mkfs.ext4 $PARTITION -L etcd_disk -F -E lazy_itable_init=1,lazy_journal_init=1
    fi
    mount $MOUNTPOINT

runcmd:
- sudo apt-get install etcd -y
- /bin/echo DAEMON_ARGS=--name "{{WrapAsVerbatim "variables('masterVMNames')[copyIndex(variables('masterOffset'))]"}}" --initial-advertise-peer-urls "{{WrapAsVerbatim "variables('masterEtcdPeerURLs')[copyIndex(variables('masterOffset'))]"}}" --listen-peer-urls "{{WrapAsVerbatim "variables('masterEtcdPeerURLs')[copyIndex(variables('masterOffset'))]"}}" --advertise-client-urls "{{WrapAsVerbatim "variables('masterEtcdClientURLs')[copyIndex(variables('masterOffset'))]"}}" --listen-client-urls "{{WrapAsVerbatim "concat(variables('masterEtcdClientURLs')[copyIndex(variables('masterOffset'))], ',http://127.0.0.1:', variables('masterEtcdClientPort'))"}}" --initial-cluster-token "k8s-etcd-cluster" --initial-cluster "{{WrapAsVerbatim "variables('masterEtcdClusterStates')[div(variables('masterCount'), 2)]"}} --data-dir "/var/lib/etcddisk"" --initial-cluster-state "new" | tee -a /etc/default/etcd
- sudo /bin/chown -R etcd:etcd /var/lib/etcd/default
- /opt/azure/containers/mountetcd.sh
- sudo /bin/chown -R etcd:etcd /var/lib/etcddisk
- systemctl stop etcd
- sudo -u etcd rm -rf /var/lib/etcd/default
- systemctl restart etcd
- for i in $(seq 1 20); do curl --max-time 60 http://127.0.0.1:2379/v2/machines; [ $? -eq 0 ] && break || sleep 5; done
- retrycmd_if_failure() { for i in 1 2 3 4 5; do $@; [ $? -eq 0  ] && break || sleep 5; done ; }
- retrycmd_if_failure apt-get update
- retrycmd_if_failure apt-get install -y apt-transport-https ca-certificates
- retrycmd_if_failure curl --max-time 60 -fsSL https://aptdocker.azureedge.net/gpg | apt-key add -
- echo "deb {{WrapAsVariable "dockerEngineDownloadRepo"}} ubuntu-xenial main" | sudo tee /etc/apt/sources.list.d/docker.list
- "echo \"Package: docker-engine\nPin: version {{WrapAsVariable "dockerEngineVersion"}}\nPin-Priority: 550\n\" > /etc/apt/preferences.d/docker.pref"
- retrycmd_if_failure apt-get update
- retrycmd_if_failure apt-get install -y ebtables
- retrycmd_if_failure apt-get install -y docker-engine
- systemctl restart docker
- mkdir -p /etc/kubernetes/manifests
- usermod -aG docker {{WrapAsVariable "username"}}
- /usr/lib/apt/apt.systemd.daily
- touch /opt/azure/containers/runcmd.complete
